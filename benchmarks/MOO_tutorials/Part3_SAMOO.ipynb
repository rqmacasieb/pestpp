{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "984af293",
   "metadata": {},
   "source": [
    "# Speeding Up the Search for \"Compromise Solutions\" Before It's Too Late\n",
    "### A walk through on Surrogate-Assisted MOO (SAMOO)\n",
    "\n",
    "Now that we know Pareto optimality and that there's a tool to efficiently perform MOO, we have to face another problem: \n",
    "\n",
    "For this tutorial, we will still be using the Fonseca-Fleming problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da493aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyemu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197eecfb",
   "metadata": {},
   "source": [
    "Recall that the Fonseca-Fleming problem has two objectives with different decision variable values for their respective minimums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd0c09f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fonseca_fleming(x):\n",
    "    x = np.array(x)\n",
    "    n = len(x)\n",
    "    # Fonseca-Fleming objective functions\n",
    "    # f1(x) = 1 - exp(-sum((xi - 1/sqrt(n))^2))\n",
    "    # f2(x) = 1 - exp(-sum((xi + 1/sqrt(n))^2))\n",
    "    term1 = np.sum((x - 1/np.sqrt(n))**2)\n",
    "    term2 = np.sum((x + 1/np.sqrt(n))**2)\n",
    "    \n",
    "    obj1 = 1 - np.exp(-term1)\n",
    "    obj2 = 1 - np.exp(-term2)\n",
    "    \n",
    "    return obj1, obj2\n",
    "\n",
    "n_samples = 1000\n",
    "x1_range = np.linspace(-4, 4, int(np.sqrt(n_samples)))\n",
    "x2_range = np.linspace(-4, 4, int(np.sqrt(n_samples)))\n",
    "x1, x2 = np.meshgrid(x1_range, x2_range)\n",
    "x1 = x1.flatten()\n",
    "x2 = x2.flatten()\n",
    "\n",
    "x1 = x1[:n_samples]\n",
    "x2 = x2[:n_samples]\n",
    "\n",
    "n_actual = min(len(x1), len(x2))\n",
    "objectives = np.array([fonseca_fleming([x1[i], x2[i]]) for i in range(n_actual)])\n",
    "obj1 = objectives[:, 0]\n",
    "obj2 = objectives[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cbfbc2",
   "metadata": {},
   "source": [
    "Let us first generate the template files we need for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bef47db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fonseca_fleming_demo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_d = \"./base_files\"\n",
    "assert os.path.exists(base_d)\n",
    "\n",
    "temp_d = \"fonseca_fleming_demo\"\n",
    "if os.path.exists(temp_d):\n",
    "    shutil.rmtree(temp_d)\n",
    "shutil.copytree(base_d,temp_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b6006",
   "metadata": {},
   "source": [
    "We can easily find Pareto optimal set of decision variables by running PESTPP-MOU. Let's generate an initial swarm size of 50 and perform 20 iterations of MOO. To ensure that ou initial population is evenly distributed and sufficiently samples the decision space, it is advisable to use Latin Hypercube Sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831677f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gen=0_member=0</th>\n",
       "      <td>-3.328019</td>\n",
       "      <td>-1.181402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen=0_member=1</th>\n",
       "      <td>-1.866797</td>\n",
       "      <td>-1.402948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen=0_member=2</th>\n",
       "      <td>1.721195</td>\n",
       "      <td>2.384178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen=0_member=3</th>\n",
       "      <td>-2.658355</td>\n",
       "      <td>-3.251364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen=0_member=4</th>\n",
       "      <td>3.365238</td>\n",
       "      <td>1.249119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      x1        x2\n",
       "real_name                         \n",
       "gen=0_member=0 -3.328019 -1.181402\n",
       "gen=0_member=1 -1.866797 -1.402948\n",
       "gen=0_member=2  1.721195  2.384178\n",
       "gen=0_member=3 -2.658355 -3.251364\n",
       "gen=0_member=4  3.365238  1.249119"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append(temp_d)\n",
    "from LHS_sampler import generate_lhsstarter\n",
    "\n",
    "os.chdir(temp_d)\n",
    "generate_lhsstarter(seed=42, n_samples=50, n_dimensions=2)\n",
    "os.chdir(\"..\")\n",
    "\n",
    "starter_pop = pd.read_csv(os.path.join(temp_d, \"FON_template\", \"starter.dv_pop.csv\"), index_col=\"real_name\")\n",
    "starter_pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fefa492",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8\n",
    "shutil.copy2(os.path.join(temp_d, \"FON_template\", \"starter.dv_pop.csv\"),\n",
    "              os.path.join(temp_d, \"FON_template\", \"initial.dv_pop.csv\"))\n",
    "\n",
    "tmpl_in = os.path.join(temp_d, \"FON_template\")\n",
    "sys.path.insert(0,tmpl_in)\n",
    "from forward_run import ppw_worker as ppw_function\n",
    "pyemu.os_utils.start_workers(tmpl_in, \"pestpp-mou\", \"fon.pst\", num_workers = num_workers,\n",
    "                             worker_root = temp_d, master_dir = os.path.join(temp_d, \"pbm_run\"),\n",
    "                             ppw_function = ppw_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6131c5af",
   "metadata": {},
   "source": [
    "Let's plot the resulting Pareto front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3a8f83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2a6ea5ca254219ab0c2ee9307beed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=20, continuous_update=False, description='Generation:', max=20), HBox(children=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, IntSlider, HBox, VBox, Output\n",
    "from IPython.display import display\n",
    "from scipy.interpolate import griddata\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "run_data = pd.read_csv(os.path.join(temp_d, \"pbm_run\", \"fon.pareto.summary.csv\"))\n",
    "max_gen = max(run_data['generation'])\n",
    "\n",
    "csvfiles = sorted(glob.glob(os.path.join(temp_d, \"pbm_run\", \"*[0-999].dv_pop.csv\"), recursive=True), \n",
    "                  key=lambda x: int(x.split(\".dv\")[0].split(\".\")[1]))\n",
    "all_dv_list = []\n",
    "for file in csvfiles:\n",
    "    generation = int(file.split(\".dv\")[0].split(\".\")[1])\n",
    "    df = pd.read_csv(file).assign(generation=generation)\n",
    "    df = df[['generation'] + [col for col in df.columns if col != 'generation']] \n",
    "    all_dv_list.append(df)\n",
    "all_dv = pd.concat(all_dv_list, ignore_index=True)\n",
    "\n",
    "csvfiles = sorted(glob.glob(os.path.join(temp_d, \"pbm_run\", \"*[0-999].obs_pop.csv\"), recursive=True), \n",
    "                      key=lambda x: int(x.split(\".obs\")[0].split(\".\")[1]))\n",
    "\n",
    "all_obs_list = []\n",
    "for file in csvfiles:\n",
    "    generation = int(file.split(\".obs\")[0].split(\".\")[1])\n",
    "    df = pd.read_csv(file).assign(generation=generation)\n",
    "    df = df[['generation'] + [col for col in df.columns if col != 'generation']] \n",
    "    all_obs_list.append(df)\n",
    "all_obs = pd.concat(all_obs_list, ignore_index=True)\n",
    "\n",
    "all_data = pd.merge(all_dv, all_obs, on=['generation', 'real_name'])\n",
    "max_gen = max(all_data['generation'])\n",
    "\n",
    "x = all_data['x1'].values\n",
    "y = all_data['x2'].values\n",
    "z1 = all_data['obj1'].values\n",
    "z2 = all_data['obj2'].values\n",
    "\n",
    "xi = np.linspace(min(x), max(x), 100)\n",
    "yi = np.linspace(min(y), max(y), 100)\n",
    "xi_grid, yi_grid = np.meshgrid(xi, yi)\n",
    "\n",
    "zi1 = griddata((x, y), z1, (xi_grid, yi_grid), method='cubic')\n",
    "zi2 = griddata((x, y), z2, (xi_grid, yi_grid), method='cubic')\n",
    "\n",
    "out_pareto = Output()\n",
    "out_obj_space = Output()\n",
    "out_contour = Output()\n",
    "\n",
    "def plot_all(generation):\n",
    "\n",
    "    with out_pareto:\n",
    "        out_pareto.clear_output(wait=True)\n",
    "        pareto = run_data.loc[(run_data['generation']==generation) & (run_data['nsga2_front'] == 1)]\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.scatter(pareto['obj1'], pareto['obj2'], c='firebrick', s=50, alpha=0.7)\n",
    "        plt.xlabel('Objective 1')\n",
    "        plt.ylabel('Objective 2')\n",
    "        plt.title(f'Pareto Front at Generation {generation}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    with out_obj_space:\n",
    "        out_obj_space.clear_output(wait=True)\n",
    "        all_points = run_data.loc[(run_data['generation']==generation)]\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.scatter(all_points['obj1'], all_points['obj2'], edgecolor='green', c = 'none', s=50, alpha=0.7)\n",
    "        plt.xlabel('Objective 1')\n",
    "        plt.ylabel('Objective 2')\n",
    "        plt.title(f'Objective Space at Generation {generation}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    with out_contour:\n",
    "        out_contour.clear_output(wait=True)\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        contour1 = ax.contourf(xi_grid, yi_grid, zi1, 15, cmap='plasma', alpha=0.5)\n",
    "        fig.colorbar(contour1, ax=ax, label='Objective 1')\n",
    "        contour2 = ax.contour(xi_grid, yi_grid, zi2, 15, cmap='viridis', alpha=0.7)\n",
    "        fig.colorbar(contour2, ax=ax, label='Objective 2')\n",
    "\n",
    "        pareto_members = pareto['member'].values\n",
    "        pareto_dv = all_data[all_data['real_name'].isin(pareto_members)]\n",
    "        ax.scatter(pareto_dv['x1'], pareto_dv['x2'], edgecolor='firebrick', facecolor='none', s=40, alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('x1')\n",
    "        ax.set_ylabel('x2')\n",
    "        ax.set_title(f'Pareto Optimal Decisions at Generation {generation}')\n",
    "        ax.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "generation_slider = IntSlider(min=0, max=max_gen, step=1, value=max_gen, \n",
    "                             description='Generation:',\n",
    "                             continuous_update=False)\n",
    "plot_all(max_gen)\n",
    "\n",
    "generation_slider.observe(lambda change: plot_all(change['new']), names='value')\n",
    "display(VBox([\n",
    "    generation_slider,\n",
    "    HBox([out_obj_space, out_pareto]),\n",
    "    out_contour\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff5d40",
   "metadata": {},
   "source": [
    "As this benchmark is really easy, it doesn't take much time to finish the entire optimization process and it doesn't take a lot of iteration to obtain a set of Pareto optimal solutions. However, in reality, real-world models do not run this fast. Even with parallelisation, it can take a few hundred, even thousand iterations until the swarm converges to the Pareto front. If important timely decisions rely on the outcome of such optimisation process, we would need some help to speed up this process. \n",
    "\n",
    "Let's pretend for a while that the Fonseca-Fleming problem is a complex model that is expensive to evaluate. There's nothing we could do about the run time of the complex model. What we can do though is to employ an \"emulator\", a faster and cheaper model that approximates the relationships between the known (i.e., previously evaluated) input and outputs of the complex model in order to predict its response to some input values that were not previously evaluated. This emulator is also known as the surrogate model. Because the surrogate model is an approximation, its prediction has errors. These errors could mislead the decision-making to some suboptimal solutions that are not actually in the Pareto front. This is some price to pay for speeding up the process, but do'nt worry as we have means to manage these uncertainties and still obtain truly Pareto optimal solutions.\n",
    "\n",
    "There are many surrogate models available in literature. However, we will use Gaussian Process Regression as it provides a convenient way to take into account the uncertainty in predictions of the surrogate model, which, as previously said, needs to be managed well.\n",
    "\n",
    "Surrogate-Assisted Multi-Objective Optimisation (SAMOO) follows this general algorithm:\n",
    "1. LHS sampling of initial training dataset and starting population\n",
    "2. Complex model evaluation (hereinafter referred to as Outer Iteration)\n",
    "3. Pareto dominance evaluation\n",
    "     - if front converged: exit; else: continue to step 4\n",
    "4. (Re)training the GPR\n",
    "5. MOO with GPR replacing the complex model (hereinafter referred to as Inner Iterations)\n",
    "6. Resampling for new training points (also called infills)\n",
    "\n",
    "Steps 2-6 are performed iteratively until convergence is achieved in Step 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d84ae3",
   "metadata": {},
   "source": [
    "Let us first prepare our PEST files (control, template, instruction files) to be SAMOO-ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7d9969f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'generate_templates' from 'prep_templates' (c:\\Users\\rmacasieb\\Documents\\GitHub\\pestpp\\benchmarks\\MOO_tutorials\\fonseca_fleming_demo\\prep_templates.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(temp_d)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprep_templates\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_templates\n\u001b[0;32m      4\u001b[0m nmax_inner \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(temp_d)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'generate_templates' from 'prep_templates' (c:\\Users\\rmacasieb\\Documents\\GitHub\\pestpp\\benchmarks\\MOO_tutorials\\fonseca_fleming_demo\\prep_templates.py)"
     ]
    }
   ],
   "source": [
    "sys.path.append(temp_d)\n",
    "from prep_templates import generate_templates\n",
    "\n",
    "nmax_inner = 20\n",
    "os.chdir(temp_d)\n",
    "generate_templates(nmax_inner)\n",
    "os.chdir(\"..\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
